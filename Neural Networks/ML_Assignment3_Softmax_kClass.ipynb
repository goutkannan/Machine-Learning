{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy\n",
    "import random\n",
    "import timeit\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing Iris Image Dataset \n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features.\n",
    "Y = iris.target\n",
    "normalize(X,copy=True)\n",
    "\n",
    "samples = np.column_stack((X , Y))\n",
    "samples =np.array(random.sample(samples, len(samples)))\n",
    "x_train = samples[:100,0:4]\n",
    "y_train = samples[:100,4]\n",
    "x_test = samples[100:,0:4]\n",
    "y_test = samples[100:,4]\n",
    "\n",
    "labels = len(np.unique(y_train))\n",
    "features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculating the Softmax\n",
    "$ \\forall_j  \\arg\\max  (\\exp^{\\theta_J \\cdot x}/\\sum_{j=1}^{k} \\exp^{\\theta_J \\cdot x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax_predict(theta,x):\n",
    "   \n",
    "    nr=np.exp((np.dot(theta,x)))\n",
    "    probabilities =(nr)/(np.sum(nr,axis=0))  \n",
    "    \n",
    "\n",
    "    return np.argmax(probabilities,axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta,x):\n",
    "    y_predict=[]\n",
    "    for x_i in x:\n",
    "        y_predict.append(softmax_predict(theta,x_i))\n",
    "    \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3L, 4L)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indicator(x,y):\n",
    "    if x==y:\n",
    "        return y\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x,y, labels,learning_rate,maxIterations=10):\n",
    "    iterations=0\n",
    "    theta = np.random.rand(labels,features)/100\n",
    "    \n",
    "    while(iterations < maxIterations):\n",
    "        for j in range(0,(labels)):\n",
    "            for i in range(x.shape[0]):\n",
    "                y_i = indicator(y[i],j)\n",
    "               \n",
    "                if y_i!=0:\n",
    "                    htheta= softmax_predict(theta,x[i])\n",
    "                    gradient = np.dot((htheta - y_i),x[i])/x.shape[0]\n",
    "                    theta[j] = theta[j] - learning_rate*gradient\n",
    "        \n",
    "        iterations+=1 \n",
    "        \n",
    "    return theta \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = gradient_descent(x_train,y_train, labels, learning_rate=0.002,maxIterations=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = predict(theta,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_performance(y_Cap,y,cls):\n",
    "    \"\"\" Using the Confusion matrix , the metric like Accuracy , Precision , Recall , F square measures are computed \"\"\"\n",
    "    a,b,c,d = confussion_matrix(y_Cap,y,cls)\n",
    "    r =0 \n",
    "    p= 0\n",
    "    if a+b+c+d!=0:\n",
    "        print \"Accuracy \\t:\",(a+d)/(a+b+c+d)\n",
    "    else: \n",
    "        print \"Can't Compute Accurancy\"\n",
    "    if c+d !=0:\n",
    "        \n",
    "        r = (d)/(c+d)\n",
    "        print \"Recall  \\t:\",r\n",
    "        print \"False Negative \\t:\",c/(c+d)\n",
    "    else: \n",
    "        print \"Can't Compute Recall and False Negative\"\n",
    "        r=0\n",
    "    if b+d!=0:    \n",
    "        p = d/(b+d)\n",
    "        print \"Precision \\t:\",p\n",
    "    else: \n",
    "        print \"Can't Compute Precision \"\n",
    "        p=0\n",
    "    if a+b!=0:\n",
    "        print \"False Positive \\t:\",b/(a+b)\n",
    "        print \"True Negative \\t:\",a/(a+b)\n",
    "    else:\n",
    "         print \"Can't Compute False Positive and True Negatice\"\n",
    "    if p+r !=0:\n",
    "        print \"F Square \\t:\",2*(p*r)/(p+r)\n",
    "    else:\n",
    "        print\"Can't Compute F Square\"\n",
    "    return p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def confussion_matrix(y_cap,y,cls=1):\n",
    "    \"\"\" Compute the confussion matrix for the given predicted and actual classes \"\"\"\n",
    "    a=0\n",
    "    b=0\n",
    "    c=0\n",
    "    d=0\n",
    "    for i in range(0,len(y)):        \n",
    "        if y[i]==cls and y_cap[i] ==cls:\n",
    "            a+=1\n",
    "        elif y[i]!=cls and y_cap[i] ==cls:\n",
    "            c+=1\n",
    "        elif y[i]==cls and y_cap[i] !=cls:\n",
    "            b+=1\n",
    "        elif y[i]!=cls and y_cap[i] !=cls:\n",
    "            d+=1\n",
    "    return float(a),float(b),float(c),float(d)\n",
    "\n",
    "\n",
    "a,b,c,d = confussion_matrix(y_predict, y_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Performance evaluation of K Class Softmax----------- \n",
      "\n",
      "\n",
      "For a label  0.0 \n",
      "Accuracy \t: 0.94\n",
      "Recall  \t: 0.914285714286\n",
      "False Negative \t: 0.0857142857143\n",
      "Precision \t: 1.0\n",
      "False Positive \t: 0.0\n",
      "True Negative \t: 1.0\n",
      "F Square \t: 0.955223880597\n",
      "(1.0, 0.9142857142857143)\n",
      "\n",
      "\n",
      "For a label  1.0 \n",
      "Accuracy \t: 0.6\n",
      "Recall  \t: 1.0\n",
      "False Negative \t: 0.0\n",
      "Precision \t: 0.6\n",
      "False Positive \t: 1.0\n",
      "True Negative \t: 0.0\n",
      "F Square \t: 0.75\n",
      "(0.6, 1.0)\n",
      "\n",
      "\n",
      "For a label  2.0 \n",
      "Accuracy \t: 0.66\n",
      "Recall  \t: 0.514285714286\n",
      "False Negative \t: 0.485714285714\n",
      "Precision \t: 1.0\n",
      "False Positive \t: 0.0\n",
      "True Negative \t: 1.0\n",
      "F Square \t: 0.679245283019\n",
      "(1.0, 0.5142857142857142)\n"
     ]
    }
   ],
   "source": [
    "print \" Performance evaluation of K Class Softmax----------- \"\n",
    "for i in (np.unique(y_test)):\n",
    "    print '\\n'\n",
    "    print \"For a label \" ,i ,'\\n',evaluate_performance(y_predict, y_test,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
